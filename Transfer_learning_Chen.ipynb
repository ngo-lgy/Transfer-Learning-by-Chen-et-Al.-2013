{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d5e9e9f-5b06-4595-97a5-8059358e6022",
   "metadata": {},
   "source": [
    "# Transfer Learning de l'étude de Chen et Al. 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb6648-97fb-47bf-a8a0-d9e2e19bd7fc",
   "metadata": {},
   "source": [
    "#### Objectif de l'étude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f47ea1-a9b6-4321-a0a3-82e279dd8efd",
   "metadata": {},
   "source": [
    "\n",
    "Nous allons explicité comment est obtenu l'estimateur par transfert de cette étude. Comme dans les autres études, on veut combiner les régressions linéaires issues de deux sources de données. Un petit ensemble de données possédant des  observations de hautes qualité et coûteuses et un grand ensemble de données contenant moins de données coûteuses. Le but sera de faire des prédictions sur le petit ensemble de données de haute qualité en utilisant le second ensemble de données plus grand mais potentiellement biaisé. L'application concrète de cette étude se déroule au sein de Google, où il s'agit de faire des prédictions sur une population à partir d'un petit échantillon de consommateurs, qui sont sélectionnés et rémunérés pour partager leurs données de navigation sur Internet et de télévision. Le grand échantillon de consommateur provenant d'une autre population à accepter librement le processus de collecte de données. Si le grand ensemble de données est complètement différents du petit alors il ne sert à rien de l'utiliser. Il doit être similaire mais pas nécessairement identique au petit. Par conséquent utiliser le grand ensemble de données peut s'avérer avantageux même s'il comporte le risque d'introduire un certain biais. L'idée est de recueillir certaines informations issues de l'ensemble de données le plus grand afin d'enrichir l'analyse sur l'ensemble de données le plus petit tout en minimisant l'introduction du biais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f27e9ee-0223-44a8-b609-f100ecea422d",
   "metadata": {},
   "source": [
    "#### Contexte théorique et méthodes de calcul de l'estimateur par transfert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b637c5a-8f2d-4f90-a071-b0fe1a54e195",
   "metadata": {},
   "source": [
    "Le modèle de régression pour le petit ensemble de données est donné par : $$Y_i=X_i\\beta + \\epsilon_i,$$ \\ $i\\in T$, $\\beta \\in \\mathbb{R}^{D}$ et $\\epsilon_i$ de moyenne $0$ et de variance $\\sigma_T^{2}$. \n",
    "Ensuite on suppose que les données du grand ensemble de données suivent : $$Y_i=X_i(\\beta+\\gamma) + \\epsilon_i$$ $i \\in S$ et $\\gamma \\in \\mathbb{R}^{D}$ est un paramètre de biais qui représente la différence entre les coefficients de régression des deux ensembles de donnée, les $\\epsilon_i$ sont indépendants de moyenne 0 et de variance $\\sigma_S^{2}$. Les tailles d'échantillons sont comme précédemment $N_T$ pour le petit et $N_S$ pour le grand. On peut aussi définir comme précédemment $X_S \\in \\mathbb{R}^{N_S \\times D}$ et $X_T \\in \\mathbb{R}^{N_T \\times D}$ ayant des lignes faient de vecteurs $X_i$ pour $i \\in S$ et $i \\in T$ respectivement. De même, on a $Y_S \\in \\mathbb{R}^{N_S}$ et $Y_T \\in \\mathbb{R}^{N_T}$ les vecteurs correspondants des valeurs de réponse. On pose comme précédemment  $\\Sigma_S=X_S^\\top X_S$ et $\\Sigma_T=X_T^\\top X_T$. Il existe deux approches pour obtenir l'estimateur par transfert. Comme dans les deux études précédente, le petit ensemble de donnée est l'ensemble cible et le grand ensemble de donnée est l'ensemble source.\n",
    "\n",
    "- La première consiste à regrouper les données en mettant une pénalité sur $\\gamma$. Puis on estime $\\beta_{TL}$ et $\\gamma$ en minimisant : $$\\sum_{i \\in T} (Y_i - X_i \\beta)^2 + \\sum_{i \\in S} (Y_i - X_i (\\beta + \\gamma))^2 + \\lambda P(\\gamma)\n",
    "$$ où $\\lambda \\in [0, \\infty)\n",
    "$ et $P(\\gamma) \\geq 0$ est une fonction de pénalité qui peut être $\\|X_T \\gamma \\|_2^{2} $, $\\|X_T \\gamma \\|_1^{2} $, $\\|\\gamma \\|_2^{2} $ ou encore $\\|\\gamma \\|_1^{2} $. On rappelle que le paramètre $\\gamma$ mesure le degré de différence entre les coefficients de régression du grand ensemble de données et ceux du petit ensemble de données. En pénalisant $\\gamma$, on essaie de contrôler cette différence, ce qui permet d'intégrer le grand ensemble de données tout en limitant le biais potentiel introduit par ce  dernier. \n",
    "- La seconde approche étroitement lié est d'estimée $\\hat{\\beta}_S$ en minimisant $\\sum_{i \\in S} (Y_i - X_i \\beta_S)^2$, estimé $\\hat{\\beta}_T$ en minimisant $\\sum_{i \\in T} (Y_i - X_i \\beta_T)^2$ puis d'estimer $\\beta_{TL}$ par $\\hat{\\beta}_{TL}=\\omega\\hat{\\beta}_T + (1-\\omega)\\hat{\\beta}_S$ pour un certain $0 \\leq \\omega \\leq 1 $.\n",
    "\n",
    "Pour la première méthode nous présenterons la démarche permettant d'obtenir l'estimateur par transfert et pour la seconde méthode nous montrerons comment est obtenu l'estimation de $\\omega$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea3e49-c1ab-4b3e-943d-83f589e4de9b",
   "metadata": {},
   "source": [
    "#### Démarche conduisant à l'estimateur par transfert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2fdc3-fd60-44b5-aef7-027781db7861",
   "metadata": {},
   "source": [
    "Il est garanti par le lemme 2.1 de l'étude de Chen et que si $X_T$ et $X_S$ sont de rang D, alors pour tout $\\lambda \\geq 0$, $\\hat{\\beta}_{TL}$ satisfait : $$\\hat{\\beta}_{TL}=W_{\\lambda}\\hat{\\beta}_T + (\\mathbf{I}_D - W_{\\lambda})\\hat{\\beta}_S$$ avec $$W_{\\lambda}=(\\Sigma_T + \\lambda \\Sigma_T + \\lambda \\Sigma_S)^{-1}(\\Sigma_S + \\lambda \\Sigma_T).$$ Dans l'expression précédente, on voit qu'il nous reste $\\lambda$ comme seule valeur inconnu  pour pouvoir obtenir $\\hat{\\beta}_{TL}$. On va l'estimer dans la suite par le biais d'une méthode plug-in. La  mean square error prédictive est donnée par : $$\\text{MSE} = \\mathbb{E} \\left( \\| X_S(\\hat{\\beta} - \\beta) \\|^2 \\right) = \\sigma_S^2 \\sum_{j=1}^{D} \\frac{(1 + \\lambda \\nu_j)^2}{(1 + \\lambda + \\lambda \\nu_j)^2} + \\sum_{j=1}^{D} \\frac{\\lambda^2 \\kappa_j^2}{(1 + \\lambda + \\lambda \\nu_j)^2}.$$ L'estimateur plug-in de $\\lambda$ est choisi en minimisant cette mean square error prédictive et il est donné par : $$\\hat{\\lambda} = \\arg \\min_{\\lambda \\geq 0} \\sum_{j=1}^D \\frac{\\hat{\\sigma}^2_T(1 + \\lambda \\nu_j)^2 + \\lambda^2 \\hat{\\kappa}^2_j}{(1 + \\lambda + \\lambda \\nu_j)^2}$$  avec $\\hat{\\sigma}^2_T = \\frac{\\|Y_T - X_T \\hat{\\beta}_T\\|^2}{N_T - D}$, $\\hat{\\kappa}_j^2 = u_j^T \\Sigma_T^{1/2} \\hat{\\Theta} \\Sigma_T^{1/2} u_j$ avec $u_j$ et $\\nu_j$ provenant de la décomposition propre de la matrice $M \\equiv \\Sigma_T^{1/2} \\Sigma_S^{-1} \\Sigma_T^{1/2}$,\n",
    "$\\hat{\\Theta}$ donné par   $\\hat{\\Theta}_{\\text{plug}} = \\hat{\\gamma}\\hat{\\gamma}^T + \\hat{\\sigma}^2_S \\Sigma^{-1}_S$ où $\\hat{\\gamma} = \\hat{\\beta}_S - \\hat{\\beta}_T$. \\\\Il peut également être utilisé pour estimer $\\lambda$ l'estimation plug-in en biais ajusté de $\\Theta$ donné par : $$\\hat{\\Theta}_{\\text{bapi}} = \\hat{\\sigma}^2_S \\Sigma^{-1}_S + (\\hat{\\gamma}\\hat{\\gamma}^T - \\hat{\\sigma}^2_S \\Sigma^{-1}_S - \\hat{\\sigma}^2_T \\Sigma^{-1}_T)_+, $$ où l'opérateur $+$ ici désigne une transformation de la matrice $(\\hat{\\gamma}\\hat{\\gamma}^T - \\hat{\\sigma}^2_S \\Sigma^{-1}_S - \\hat{\\sigma}^2_T \\Sigma^{-1}_T)$.  Cette transformation consiste à diagonaliser la matrice, puis à modifier ses valeurs propres en conservant uniquement celles qui sont positives et en remplaçant les valeurs propres négatives par $0$. Après cela, la matrice est reconstruite à partir de ces nouvelles valeurs propres. \\\\Ainsi par la première approche on obtient :\n",
    "$$\\hat{\\beta}_{TL}=W_{\\hat{\\lambda}}\\hat{\\beta}_T + (\\mathbb{I}_D - W_{\\hat{\\lambda}})\\hat{\\beta}_S$$\n",
    "\n",
    "Il existe plusieurs estimations considérés pour $\\omega$. Nous en présentons trois ici. \n",
    "\n",
    "- La première est donnée par : $$\\hat{\\omega}_{\\text{plug}}= (\\hat{\\delta}_0^{2} + \\hat{\\sigma}_S^{2}/N_S)(\\hat{\\delta}_0^{2} + \\hat{\\sigma}_S^{2}/N_S + \\hat{\\sigma}_T^{2}/N_T )$$ où $\\hat{\\delta}_0=\\bar{Y}_S - \\bar{Y}_T$, $\\sigma_T^{2}=\\frac{1}{N_T} \\sum_{i \\in T} (Y_i - \\bar{Y}_T)^2$ et $\\sigma_S^{2}=\\frac{1}{N_S} \\sum_{i \\in T} (Y_i - \\bar{Y}_S)^2$. \n",
    "- La seconde par : $$\\hat{\\omega}_{bapi}=\\frac{\\hat{\\theta}_{bapi}}{\\hat{\\theta}_{bapi} + \\hat{\\sigma}_T^{2}/N_T}$$ où $\\hat{\\theta}_{bapi}=\\frac{\\hat{\\sigma}_S^{2}}{N_S} +(\\hat{\\delta}_0^{2} - \\frac{\\hat{\\sigma}_T^{2}}{N_T} - \\frac{\\hat{\\sigma}_S^{2}}{N_S})_+$. \n",
    "- Et la troisième estimation de $\\omega$ est donnée par : $$\\hat{\\omega}_{cv}=\\arg \\min_{\\omega \\in [0, 1]} \\frac{1}{K} \\sum_{k=1}^{K}(\\bar{Y}_{T,k} - \\omega \\bar{Y}_{T,-k} - (1- \\omega)\\bar{Y}_S)^{2}$$ où $\\bar{Y}_{T,k}$ est la moyenne de $Y_i$ sur la $kième$ partie de $T$ et $\\bar{Y}_{T,-k}$ est la moyenne de $Y_i$ sur les $K-1$ parties restantes.\n",
    "\n",
    "Puis en fonction de l'estimation choisi pour $\\omega$ on aura : $$\\hat{\\beta}_{TL}=\\hat{\\omega}\\hat{\\beta}_T + (1-\\hat{\\omega})\\hat{\\beta}_S$$\n",
    "\n",
    "En pratique on préférera utiliser la première approche car elle permet d'ajuster le modèle par transfert aux deux ensemble de données tout en minimisant la différence entre les deux modèles source et cible. Toutefois la seconde approche marche aussi très bien et offre des résultats quasi-similaire à la première. Le modèle associé à l’approche de Chen est le modèle $M_c$ et dans la suite on note par $\\hat{\\beta}_c$\n",
    "l’estimateur $\\hat{\\beta}_{TL}$ obtenu précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9043ff-ffad-41aa-9702-a72b78812ca3",
   "metadata": {},
   "source": [
    "Le code ci-dessous éffectue le programme permettant d’obtenir l’estimateur par transfert de l’étude de Chen\n",
    "et Al. 2013 puis trace l’estimation du polynome cible de l’étude de Obst et Al. 2022 en utilisant\n",
    "l’estimateur par transfert de l’étude de Chen et Al. 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed1f3c8-7192-40fb-92b4-eeb7710957e1",
   "metadata": {},
   "source": [
    "#### Chargement des librairies et modèles de régression source et cible pour l’étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a5cb21-1f07-43fa-99a4-db401e5abd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import schur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391aab57-f2f7-4ac6-b80f-eff5e016c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conception of the target model\n",
    "Nt=20\n",
    "D=4\n",
    "sigma_t=0.5\n",
    "betat0=-1\n",
    "betat1=-1.8\n",
    "betat2=1.2\n",
    "betat3=1\n",
    "X_t=np.ones((Nt,D))\n",
    "x_t=np.ones((Nt,1))\n",
    "random.seed(a=256, version=2)\n",
    "for i in range(0,Nt):\n",
    "    x_t[i,0]=-4*random.random()+1\n",
    "for j in range(1,D):\n",
    "    for i in range(0,Nt):\n",
    "        if j==1:\n",
    "            X_t[i,j]=x_t[i,0]\n",
    "        elif j==2:\n",
    "            X_t[i,j]=(x_t[i,0])**2\n",
    "        else:\n",
    "            X_t[i,j]=(x_t[i,0])**3\n",
    "big_sigma_t=np.matmul(np.transpose(X_t),X_t)\n",
    "random.seed(a=255, version=2)\n",
    "epsilon_t=np.ones((Nt,1))\n",
    "for i in range(Nt):\n",
    "    epsilon_t[i,0]=random.normalvariate(mu=0.0, sigma=m.sqrt(sigma_t))\n",
    "beta_t=np.array([[betat0],[betat1],[betat2],[betat3]])\n",
    "Y_t=X_t@beta_t+epsilon_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0eb7c8f-5ec3-48d9-b1ae-acb9dafa0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conception of the source model\n",
    "Ns=100\n",
    "D=4\n",
    "sigma_s=0.5\n",
    "X_s=np.ones((Ns,D))\n",
    "x_s=np.ones((Ns,1))\n",
    "random.seed(a=254, version=2)\n",
    "for i in range(0,Ns):\n",
    "    x_s[i,0]=3*random.random()\n",
    "for j in range(1,D):\n",
    "    for i in range(0,Ns):\n",
    "        if j==1:\n",
    "            X_s[i,j]=x_s[i,0]\n",
    "        elif j==2:\n",
    "            X_s[i,j]=(x_s[i,0])**2\n",
    "        else:\n",
    "            X_s[i,j]=(x_s[i,0])**3\n",
    "big_sigma_s=np.matmul(np.transpose(X_s),X_s)\n",
    "random.seed(a=253, version=2)\n",
    "epsilon_s=np.ones((Ns,1))\n",
    "for i in range(Ns):\n",
    "    epsilon_s[i,0]=random.normalvariate(mu=0.0, sigma=m.sqrt(sigma_s))\n",
    "random.seed(a=252, version=2)\n",
    "beta_s=np.array([[betat0 + random.normalvariate(mu=0.0, sigma=0.3)],[betat1 +random.normalvariate(mu=0.0, sigma=0.3) ],[betat2 + random.normalvariate(mu=0.0, sigma=0.3) ],[betat3 + random.normalvariate(mu=0.0,sigma=0.3) ]])\n",
    "Y_s=X_s@beta_s+epsilon_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf65e776-6ad2-4ab9-9ab4-334cf74b7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split betwenn train set and test set\n",
    "X_t_train=X_t[0:10,:]\n",
    "Y_t_train=Y_t[0:10]\n",
    "Nt_train=np.shape(X_t_train)[0]\n",
    "X_t_test=X_t[10:21,:]\n",
    "Y_t_test=Y_t[10:21]\n",
    "Nt_test=np.shape(X_t_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44572359-662c-480a-9362-39e1ce6ecfeb",
   "metadata": {},
   "source": [
    "#### Estimateur par transfert de l’étude de Chen et Al. 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d216754-e746-402c-9c3f-715a3615abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss=X_t_train\n",
    "X_b=X_s\n",
    "Y_b=Y_s\n",
    "Y_ss=Y_t_train\n",
    "n=Nt_train\n",
    "N=Ns\n",
    "d=D\n",
    "V_b=np.transpose(X_s)@X_s\n",
    "V_s=np.transpose(X_t_train)@X_t_train\n",
    "beta_chap_b=np.linalg.inv(V_b)@np.transpose(X_s)@Y_s\n",
    "beta_chap_s=np.linalg.inv(V_s)@np.transpose(X_t_train)@Y_t_train\n",
    "sigma_chap_carre_b=np.linalg.norm(Y_s - X_b@beta_chap_b,ord=2)**2/(N-d)\n",
    "sigma_chap_carre_s=np.linalg.norm(Y_t_train - X_t_train@beta_chap_s,ord=2)**2/(n-d)\n",
    "gamma_chap=beta_chap_b - beta_chap_s\n",
    "big_theta_chap=gamma_chap@np.transpose(gamma_chap) + sigma_chap_carre_b*np.linalg.inv(V_b)\n",
    "#C=(gamma_chap@np.transpose(gamma_chap) + sigma_chap_carre_b*np.linalg.inv(V_b)- sigma_chap_carre_s*np.linalg.inv(V_s))\n",
    "#C_val , C_vect =np.linalg.eig(C)\n",
    "#for i in range(len(C_val)):\n",
    "#if C_val[i]<0:\n",
    "#C_val[i]=0\n",
    "#C=C_vect@np.diag(C_val)@np.linalg.inv(C_vect)\n",
    "#print(C_val)\n",
    "#big_theta_chap=sigma_chap_carre_b*np.linalg.inv(V_b) + C\n",
    "val , vect = np.linalg.eig(V_s)\n",
    "diag=np.diag(np.sqrt((val)))\n",
    "\n",
    "V_s_decomp_sqrt = vect @ diag @ np.linalg.inv(vect)\n",
    "M=V_s_decomp_sqrt@np.linalg.inv(V_b)@V_s_decomp_sqrt\n",
    "#M=(1/2)*(M + M.T)\n",
    "D , U = np.linalg.eig(M)\n",
    "k_chap_carre=np.ones(len(U))\n",
    "for i in range(len(U)):\n",
    "    k_chap_carre[i]=U[i]@V_s_decomp_sqrt@big_theta_chap@V_s_decomp_sqrt@U[i]\n",
    "L=[]\n",
    "for lamda in np.arange(0,1000):\n",
    "    s=0\n",
    "    for j in range(len(k_chap_carre)):\n",
    "        s+=(sigma_chap_carre_s*(1+lamda*D[j])**2 + lamda**2 * k_chap_carre[j])/(1 + lamda + lamda*D[j])**2\n",
    "    L.append(s)\n",
    "lambda_chap=L.index(min(L))\n",
    "#print(np.arange(0,1000)[L.index(min(L))])\n",
    "W_lambda=np.linalg.inv(V_b + lambda_chap*V_s + lambda_chap*V_b)@(V_b +lambda_chap*V_s)\n",
    "beta_chen=W_lambda@beta_chap_s + (np.eye(d)-W_lambda)@beta_chap_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f8435-f364-478f-a6c2-ae2c24ebd034",
   "metadata": {},
   "source": [
    "#### Tracé sur le polynome cible de l’étude de Obst et Al. 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c389f8-7b65-47df-bf34-b2f569cc79c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19d3816a810>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " x = np.linspace(-3, 3, 400)\n",
    "y_estim_by_M2=beta_chen[0] + beta_chen[1]*x + beta_chen[2]*x**2 +beta_chen[3]*x**3\n",
    "plt.plot(x,y_estim_by_M2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
